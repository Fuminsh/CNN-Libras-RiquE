# CNN-Libras-RiquE

This is a project on GitHub that utilizes Convolutional Neural Networks (CNN) to interpret Brazilian Sign Language (Libras) gestures. Developed in Python with TensorFlow and OpenCV, the system recognizes gestures captured by a camera, offering an interface to translate gestures into text. The goal is to facilitate communication between the deaf community and listeners.

This project is under development, with the artificial intelligence currently in the training phase. We are working to improve the accuracy and effectiveness of the system. We appreciate your interest and patience during this development process.
